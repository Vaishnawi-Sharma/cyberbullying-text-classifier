# ğŸ¤– Toxic Comment Detection using Machine Learning  

## ğŸ“Œ Project Overview  
This project is focused on building a *Machine Learning model* to automatically detect *toxic / cyberbullying comments*.  

ğŸ‘‰ Why?  
Cyberbullying is a growing issue on online platforms. With the help of *Machine Learning*, this project demonstrates how technology can assist in identifying bullying text and creating awareness.  

---

## ğŸ›  Tech Stack  
- *Languages & Libraries*  
  - Python ğŸ  
  - NumPy, Pandas (data handling)  
  - Matplotlib (basic plots)  
  - Scikit-learn (ML models: Logistic Regression, SVM)  
  - Seaborn
  - 
## ğŸ“‚ Dataset  
- Dataset: Toxic Comment Classification Dataset (For more info visit the data readme.md)  

---

## âš™ Workflow  

1. *Data Preprocessing*  
   - Lowercasing text  
   - Removing extra punctuation & spaces  
   - Handling emojis â†’ replaced with word equivalents (ğŸ™‚ â†’ smile, ğŸ™ â†’ namaste)  
   - Keeping meaningful numbers (100, 0)  

2. *Feature Engineering*  
   - *TF-IDF Vectorization* (instead of Bag-of-Words, to capture rare bullying words with higher importance).  

3. *Model Training*  
   - Logistic Regression  
   - Support Vector Machine (SVM)  
   - Train-Test Split (stratified, to handle imbalance)  

4. *Evaluation Metrics*  
   - Accuracy  
   - Precision  
   - Recall  
   - F1-score  

